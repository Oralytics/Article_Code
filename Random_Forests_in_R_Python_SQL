# This file contains R, Python and SQL code
# It illustrates how to create and use Random Forests in all 3 languages

########################################
############ R code example ############
########################################
# Demo code for illustrating Random Forests

# open RandomForest library
library(randomForest)

# load the data set from CSV file
BankData <- read.csv(file="/Users/brendan.tierney/Downloads/bank-additional/bank-additional-full.csv", header=TRUE, sep=";")
# Let us investage this dataset and gather some informations and statistics
head(BankData)
ncol(BankData)
nrow(BankData)
names(BankData)
str(BankData)
dim(BankData)
summary(BankData)

# Set the sample size to be 40% of the full data set 
#    The Testing data set will have 30% of the records 
#    The Training data set will have 70% of the records 
SampleSize <- nrow(BankData)*0.30

# Create an index of records for the Sample 
Index_Sample <- sample(1:nrow(BankData), SampleSize) 
group <- as.integer(1:nrow(BankData) %in% Index_Sample) 

# Create a partitioned data set of those records not selected to be in sample 
Training_Sample <- BankData[group==FALSE,] 
# Get the number of records in the Training Sample data set 
nrow(Training_Sample) 

# Create a partitioned data set of those records who were selected to be in the sample 
Testing_Sample <- BankData[group==TRUE,] 
# Get the number of records in the Testing Sample data set 
nrow(Testing_Sample)

# The read.csv function converted all string and categorical variables to factors
# need to check if any numeric variables should be converted to factors


# set the random seed
# set.seed(42)

# generate/fit the model with 50 trees
rf_model <- randomForest(y~., data=Training_Sample, ntree=50)

# print basic model details, including confusion matrix
rf_model
names(rf_model)
rf_model$call
rf_model$type
rf_model$terms
rf_model$ntree
rf_model$mtry
rf_model$classes
rf_model$DOP
rf_model$confusion
rf_model$RFOPKG
summary(rf_model)

#Evaluate variable importance
importance(rf_model)
varImpPlot(rf_model) 
# Higher the value of mean decrease accuracy or mean decrease gini score, 
#  higher the importance of the variable in the model. In the plot shown 
#  above, Account Balance is most important variable.


# Score/label new data set = Testing Data set
RF_scored <- predict(rf_model, newdata=Testing_Sample, type="response")
# add the predicted value to the dataset
RF_scored2 <- cbind(Testing_Sample, RF_scored)
# create cross tab table on actual values vs predicted values i.e. confusion matrix
table(RF_scored2$y, RF_scored2$RF_scored)

# Generate the probabilities for the predicted values
RF_prob <- predict(rf_model, newdata=Testing_Sample, type="prob")
# Add probability scores to the dataset
RF_scored4 <- cbind(RF_scored2, RF_prob)
head(RF_scored4)
tail(RF_scored4)

# Let us now generate the ROC chart for the Test dataset
library(ROCR)

# generate the probabilities scores
rf.pr = predict(rf_model, type="prob", newdata=Testing_Sample)[,2]

# use the ROCR prediction function
RF_pred <- prediction(rf.pr, Testing_Sample$y) 

# performance in terms of true and false positive rates
RF_scored_perf <- performance(RF_pred, "tpr", "fpr")

#plot the ROC chart
plot(RF_scored_perf, main="ROC Curve for Random Forest", col=2, lwd=2)
abline(a=0, b=1, lwd=2, lty=2, col="gray")

#compute area under curve
auc <- performance(RF_pred,"auc")
auc <- unlist(slot(auc, "y.values"))

minauc<-min(round(auc, digits = 2))
maxauc<-max(round(auc, digits = 2))
minauct <- paste(c("min(AUC) = "),minauc,sep="")
maxauct <- paste(c("max(AUC) = "),maxauc,sep="")
minauct
maxauct


########################################
######### Python code example ##########
########################################
pip3 install -U scikit-learn
pip3 install -U numpy
pip3 install -U scipy
pip3 install -U matplotlib
pip3 install -U pandas

# read the data set into the panda
import pandas as pd

Bank_df = pd.read_csv('/users/brendan.tierney/Downloads/bank-additional/bank-additional-full.csv', sep=";")

# display the data
Bank_df

# explore the data
Bank_df.info()

# gather basic statistics about each column. 
#  very like summary function in R
Bank_df.describe()

# number of rows and columns
Bank_df.shape

# list the column names
Bank_df.columns

# recode reponse variable into 1/0

Bank_df2 = Bank_df
Bank_df2['TARGET'] = pd.factorize(Bank_df2['y'])[0]

# remove the 'y' column
Bank_df2 = Bank_df2.drop('y', 1)

# Perform one-hot encoding for categorical features. 
# These are   job, marital, education, default, housing, load, contact, month, day_of_week, poutcome

# One-hot encode the data using pandas get_dummies
Bank_df3 = pd.get_dummies(Bank_df2, dummy_na=True)
Bank_df3.columns

# check out alternative training/test split method with scikitLearn
from sklearn.model_selection import train_test_split

training_sample2, testing_sample2 = train_test_split(Bank_df3, test_size=0.3, random_state=42)

print("Training data set size = ", len(training_sample2))
print("Testing data set size = ", len(testing_sample2))

# list the attributes needed for inputs

# Labels are the values we want to predict i.e. target variable
train_labels = np.array(training_sample2['TARGET'])

# remove the target variable from the data set. axis=1 means drop column
train_features = training_sample2.drop('TARGET', axis=1)
training_sample2 = train_features

# Saving feature names for later use
train_feature_list = list(train_features.columns)

# Convert to numpy array
train_features = np.array(train_features)

# setup Random Forest algorithm
# Import the model we are using
#from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import RandomForestClassifier

# Instantiate model with 50 decision trees
rf = RandomForestClassifier(n_estimators = 50, random_state = 42)

# create or fit the model
# train the model on training sample data set
rf.fit(train_features, train_labels);

# list decision trees estimators
print(rf.estimators_)
print('--------------------')
print('Num of classes')
print(rf.n_classes_)
print('--------------------')
print('Class labels')
print(rf.classes_)
print('--------------------')
print('Num of features when fit is perform')
print(rf.n_features_)
print('--------------------')
print('Num of outputs when fit is performed')
print(rf.n_outputs_)
print('--------------------')
print('Feature Importance')
print(rf.feature_importances_)

from sklearn.model_selection import cross_validate

accuracy = cross_validate(rf, test_features, test_labels, cv=10)['test_score']
print('The accuracy is: ',sum(accuracy)/len(accuracy)*100,'%')

The accuracy is:  91.00104692394183 %

# plot ROC chart
plt.title('Receiver Operating Characteristic')
plt.plot(false_positive_rate, true_positive_rate, 'b',
label='AUC = %0.2f'% roc_auc)
plt.legend(loc='lower right')
plt.plot([0,1],[0,1],'r--')
plt.xlim([-0.1,1.2])
plt.ylim([-0.1,1.2])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Get numerical feature importances
import matplotlib.pyplot as plt
%matplotlib inline

importances = list(rf.feature_importances_)

# Set the style
plt.style.use('fivethirtyeight')
plt.figure(figsize=(16,8))

# list of x locations for plotting
x_values = list(range(len(importances)))

# Make a bar chart
plt.bar(x_values, importances, orientation = 'vertical')

# Tick labels for x axis
plt.xticks(x_values, feature_list, rotation='vertical')

# Axis labels and title
plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');



########################################
########### SQL code example ###########
########################################
create or replace view bank_train_v
as select * from banking_additional
where ora_hash(cust_id,99) <= 70;

create or replace view bank_test_v
as select * from banking_additional
where ora_hash(cust_id,99) > 70;

-- create the settings table for a Random Forest model
CREATE TABLE demo_RF_settings 
( setting_name  VARCHAR2(30),
  setting_value VARCHAR2(4000));

-- insert the settings records for a Neural Network
-- ADP is turned on. By default ADP is turned off.
BEGIN
  INSERT INTO demo_RF_settings (setting_name, setting_value)
  values (dbms_data_mining.algo_name, 
          dbms_data_mining.algo_random_forest);
	
  INSERT INTO demo_neural_network_settings (setting_name, setting_value)
  VALUES (dbms_data_mining.prep_auto, dbms_data_mining.prep_auto_on);
END;

BEGIN
   DBMS_DATA_MINING.CREATE_MODEL(
      model_name          => 'DEMO_RF_MODEL',
      mining_function     => dbms_data_mining.classification,
      data_table_name     => 'bank_train_v',
      case_id_column_name => 'cust_id',
      target_column_name  => 'target',
      settings_table_name => 'demo_rf_settings');
END;

SELECT cust_id, target,
       prediction(DEMO_RF_MODEL USING *)  predicted_value,
       prediction_probability(DEMO_RF_MODEL USING *) probability
FROM   bank_test_v;

